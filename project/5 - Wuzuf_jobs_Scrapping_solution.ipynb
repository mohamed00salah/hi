{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "05f5456e",
      "metadata": {
        "id": "05f5456e"
      },
      "source": [
        "## Wuzzuf Data Science Jobs Scrapping\n",
        "- You are required to scrap all data science jobs from wuzzuf and save the results in csv file\n",
        "- the required fields are\n",
        "<ul>\n",
        "    <li>job title</li>\n",
        "    <li>job link</li>\n",
        "    <li>Location</li>\n",
        "    <li>skills required </li>\n",
        "    <li>company_name</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "metadata": {
        "id": "hd08tbCtfq9c"
      },
      "id": "hd08tbCtfq9c",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = requests.get(f\"https://wuzzuf.net/search/jobs/?a=navbl%7Cspbl&q=data%20science%20jobs&start=0\")\n",
        "soup = BeautifulSoup(request.content, 'html.parser')\n",
        "span = soup.find('span', attrs={'class': 'css-xkh9ud'} )\n",
        "span.find('strong').get_text()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0KNxnw3Hsjut",
        "outputId": "c6dc63f0-545f-4b53-d850-deaa9db1cdc6"
      },
      "id": "0KNxnw3Hsjut",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'559'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "page_number = 0\n",
        "links = []\n",
        "titles = []\n",
        "locations = []\n",
        "companies = []\n",
        "descriptions = []\n",
        "\n",
        "data = []\n",
        "\n",
        "\n",
        "while True:\n",
        "  request = requests.get(f\"https://wuzzuf.net/search/jobs/?a=navbl%7Cspbl&q=data%20science%20jobs&start={page_number}\")\n",
        "  soup = BeautifulSoup(request.content, 'html.parser')\n",
        "\n",
        "\n",
        "  for style in soup.find_all('style'):\n",
        "    style.extract()\n",
        "\n",
        "  all_jobs = soup.find_all('div', attrs={'class': 'css-pkv5jc'})\n",
        "  \n",
        "  for job in all_jobs:\n",
        "    link = job.find('a', attrs = {'target': '_blank', 'class': 'css-o171kl'}).get('href')\n",
        "    title = job.find('a', attrs = {'target': '_blank', 'class': 'css-o171kl'}).get_text()\n",
        "    location = job.find('span', attrs={'class': 'css-5wys0k'}).get_text()\n",
        "    company_name = job.find('a', attrs = {'target': '_blank', 'class': 'css-17s97q8'}).get_text()\n",
        "    description = job.find('div',  attrs = {'class': 'css-y4udm8'}).get_text()\n",
        "\n",
        "    links.append(link)\n",
        "    titles.append(title)\n",
        "    locations.append(location)\n",
        "    companies.append(company_name)\n",
        "    descriptions.append(description)\n",
        "\n",
        "    data.append([link, title, location, company_name, description])\n",
        "\n",
        "\n",
        "  page_info = soup.find('li', attrs={'class': 'css-8neukt'}).get_text()\n",
        "  current_results, all_results = page_info.split('-')[1].split('of')[0], page_info.split('-')[1].split('of')[1]\n",
        "  current_results = int(current_results)\n",
        "  all_results = int(all_results)\n",
        "\n",
        "  print(current_results)\n",
        "\n",
        "  if current_results == all_results:\n",
        "    break\n",
        "\n",
        "  page_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Xim3Yack2k",
        "outputId": "f09359f5-d626-46c4-d252-689f33daba90"
      },
      "id": "Y6Xim3Yack2k",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "30\n",
            "45\n",
            "60\n",
            "75\n",
            "90\n",
            "105\n",
            "120\n",
            "135\n",
            "150\n",
            "165\n",
            "180\n",
            "195\n",
            "210\n",
            "225\n",
            "240\n",
            "255\n",
            "270\n",
            "285\n",
            "300\n",
            "315\n",
            "330\n",
            "345\n",
            "360\n",
            "375\n",
            "390\n",
            "405\n",
            "420\n",
            "435\n",
            "450\n",
            "465\n",
            "480\n",
            "495\n",
            "510\n",
            "525\n",
            "540\n",
            "555\n",
            "559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVkhvuySnbse",
        "outputId": "bc228a4d-89c8-44c0-fd30-f21476922178"
      },
      "id": "OVkhvuySnbse",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/jobs/p/ZuPAyVt9b0Xd-Data-Science-Supervisor-Raya-Customer-Experience-Giza-Egypt?o=1&l=sp&t=sj&a=data science jobs|search-v3|navbl|spbl',\n",
              " 'Data Science Supervisor',\n",
              " '6th of October, Giza, Egypt ',\n",
              " 'Raya Customer Experience -',\n",
              " 'Full TimeExperienced · 4 - 7 Yrs of Exp · IT/Software Development · Analyst/Research · BI · Analysis · SQL · Data · ETL · Information Technology (IT) · Programming · MySQL']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"jobs.csv\", \"w\") as fid:\n",
        "  writer = csv.writer(fid)\n",
        "  header = ['link', 'title', 'location', 'company', 'description']\n",
        "  writer.writerow(header) \n",
        "  writer.writerows(data) "
      ],
      "metadata": {
        "id": "PGBIkxTaoFOX"
      },
      "id": "PGBIkxTaoFOX",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_AuEoMbNof_N"
      },
      "id": "_AuEoMbNof_N",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbVNEQleeRug"
      },
      "id": "xbVNEQleeRug",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_DXU67tUglU1"
      },
      "id": "_DXU67tUglU1",
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}